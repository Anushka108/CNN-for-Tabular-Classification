{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "CNN for Tabular Classification ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anushka108/CNN-for-Tabular-Classification/blob/main/CNN_for_Tabular_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Convolutional Neural Networks (CNNs) for Tabular Data\n",
        "\n",
        "In this notebook, we will explore how to use Convolutional Neural Networks (CNNs) for tabular data. While CNNs are commonly used for image and text data, they can also be effective for tabular data by capturing local patterns and interactions between features.\n",
        "\n",
        "## Table of Contents\n",
        "1. Introduction\n",
        "2. Data Loading and Exploration\n",
        "3. Data Preprocessing\n",
        "4. Building a CNN Model\n",
        "5. Training the Model\n",
        "6. Evaluating the Model\n",
        "7. Hyperparameter Tuning\n",
        "8. Conclusion\n"
      ],
      "metadata": {
        "id": "dTc4dlyhpHn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "Convolutional Neural Networks (CNNs) are traditionally used for image data due to their ability to capture spatial hierarchies through convolutional layers. However, recent research has shown that CNNs can also be applied effectively to tabular data, often outperforming traditional machine learning models in certain cases.\n",
        "\n",
        "### Why Apply CNNs to Tabular Data?\n",
        "\n",
        "1. **Local Patterns and Interactions:**\n",
        "   - Tabular data often contains local patterns and interactions between features that can be effectively captured by convolutional layers. For instance, in a dataset of house prices, the relationship between the number of rooms and the size of the house might be a local pattern that a CNN can learn.\n",
        "\n",
        "2. **Parameter Sharing and Sparsity:**\n",
        "   - CNNs use parameter sharing and sparsity of connections, which reduces the number of parameters and the risk of overfitting, especially when dealing with high-dimensional data. This can lead to more efficient learning compared to fully connected layers.\n",
        "\n",
        "3. **Handling High Dimensionality:**\n",
        "   - Tabular datasets can have a high number of features. CNNs can help by learning complex feature interactions without the need for extensive feature engineering.\n",
        "\n",
        "4. **Regularization:**\n",
        "   - The convolutional layers act as a form of regularization, potentially improving the generalization performance of the model on unseen data.\n",
        "\n",
        "### How to Apply CNNs to Tabular Data?\n",
        "\n",
        "1. **Data Preprocessing:**\n",
        "   - **Normalization:** Standardize the features to have zero mean and unit variance. This ensures that the CNN can learn effectively since it is sensitive to the scale of input data.\n",
        "   - **Reshaping:** Convert the tabular data into a format suitable for CNN input, typically reshaping it to have an extra dimension representing the \"channels\" similar to how image data is structured.\n",
        "\n",
        "2. **Building the CNN Model:**\n",
        "   - **Convolutional Layers:** Add convolutional layers to capture local feature interactions. Use filters and kernel sizes that are appropriate for the tabular data.\n",
        "   - **Flattening Layer:** Flatten the output from convolutional layers to connect to fully connected (dense) layers.\n",
        "   - **Fully Connected Layers:** Add dense layers to further process the features extracted by the convolutional layers.\n",
        "   - **Output Layer:** Use a sigmoid activation function for binary classification or softmax for multi-class classification.\n",
        "\n",
        "3. **Model Compilation:**\n",
        "   - **Optimizer:** Common optimizers like Adam or RMSprop are used to train the model.\n",
        "   - **Loss Function:** Use appropriate loss functions such as binary cross-entropy for binary classification tasks.\n",
        "\n",
        "4. **Training and Evaluation:**\n",
        "   - Train the CNN model on the training data and evaluate its performance on the test data.\n",
        "\n",
        "### Example: CNN for Breast Cancer Classification\n",
        "\n",
        "In this notebook, we apply a CNN to the Breast Cancer dataset. We preprocess the data, build a simple CNN model, and train it to classify whether a tumor is malignant or benign. The steps are as follows:\n",
        "\n",
        "1. **Data Loading and Preprocessing:** Load the dataset, split into training and test sets, standardize the features, and reshape the data.\n",
        "2. **Building the CNN Model:** Define a CNN with one convolutional layer, one flattening layer, and two dense layers.\n",
        "3. **Training and Evaluation:** Train the model on the training data and evaluate its accuracy on the test data.\n"
      ],
      "metadata": {
        "id": "n9NI5L5IpHn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Loading and Exploration\n",
        "\n",
        "First, we'll load the Breast Cancer dataset from `sklearn.datasets` and explore its structure.\n"
      ],
      "metadata": {
        "id": "AZONSN-WpHn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "X.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T23:06:46.470793Z",
          "iopub.execute_input": "2024-07-02T23:06:46.471629Z",
          "iopub.status.idle": "2024-07-02T23:06:47.653647Z",
          "shell.execute_reply.started": "2024-07-02T23:06:46.471578Z",
          "shell.execute_reply": "2024-07-02T23:06:47.652311Z"
        },
        "trusted": true,
        "id": "1-6z0nNfpHn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's take a look at the basic information and statistics of the dataset."
      ],
      "metadata": {
        "id": "M40Ym41rpHn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T23:06:47.656082Z",
          "iopub.execute_input": "2024-07-02T23:06:47.656554Z",
          "iopub.status.idle": "2024-07-02T23:06:47.688022Z",
          "shell.execute_reply.started": "2024-07-02T23:06:47.656522Z",
          "shell.execute_reply": "2024-07-02T23:06:47.68667Z"
        },
        "trusted": true,
        "id": "AtQPzrUJpHn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T23:06:47.689732Z",
          "iopub.execute_input": "2024-07-02T23:06:47.690197Z",
          "iopub.status.idle": "2024-07-02T23:06:47.783145Z",
          "shell.execute_reply.started": "2024-07-02T23:06:47.690156Z",
          "shell.execute_reply": "2024-07-02T23:06:47.781904Z"
        },
        "trusted": true,
        "id": "ETao0qlipHn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Preprocessing\n",
        "\n",
        "Before feeding the data into a CNN, we need to preprocess it. This includes scaling numerical features.\n"
      ],
      "metadata": {
        "id": "Uu-dqicVpHn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scaling numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T23:06:47.786443Z",
          "iopub.execute_input": "2024-07-02T23:06:47.786943Z",
          "iopub.status.idle": "2024-07-02T23:06:47.911593Z",
          "shell.execute_reply.started": "2024-07-02T23:06:47.7869Z",
          "shell.execute_reply": "2024-07-02T23:06:47.910085Z"
        },
        "trusted": true,
        "id": "VoHatP0tpHn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Building a CNN Model\n",
        "\n",
        "Now, we'll build a CNN model using TensorFlow/Keras. We'll treat the tabular data as a 2D image with a single channel.\n"
      ],
      "metadata": {
        "id": "GTzK9vMtpHn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Reshape\n",
        "\n",
        "# Reshaping the data to 2D\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Building the CNN model\n",
        "model = Sequential([\n",
        "    Reshape((X_train.shape[1], 1, 1), input_shape=(X_train.shape[1], 1)),\n",
        "    Conv2D(32, kernel_size=(1, 1), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T23:06:47.913095Z",
          "iopub.execute_input": "2024-07-02T23:06:47.913426Z",
          "iopub.status.idle": "2024-07-02T23:07:02.246906Z",
          "shell.execute_reply.started": "2024-07-02T23:06:47.913397Z",
          "shell.execute_reply": "2024-07-02T23:07:02.245497Z"
        },
        "trusted": true,
        "id": "1aj4anrvpHoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training the Model\n",
        "\n",
        "We will now train the CNN model on the training data.\n"
      ],
      "metadata": {
        "id": "RtNbxR18pHoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_cnn, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T23:07:02.248451Z",
          "iopub.execute_input": "2024-07-02T23:07:02.24907Z",
          "iopub.status.idle": "2024-07-02T23:07:08.829895Z",
          "shell.execute_reply.started": "2024-07-02T23:07:02.249037Z",
          "shell.execute_reply": "2024-07-02T23:07:08.828619Z"
        },
        "trusted": true,
        "id": "T3o8olmjpHoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluating the Model\n",
        "\n",
        "After training, we'll evaluate the model on the test data to see how well it performs.\n"
      ],
      "metadata": {
        "id": "YPX6ua0OpHoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "test_loss, test_acc = model.evaluate(X_test_cnn, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T23:07:08.832132Z",
          "iopub.execute_input": "2024-07-02T23:07:08.832539Z",
          "iopub.status.idle": "2024-07-02T23:07:08.942861Z",
          "shell.execute_reply.started": "2024-07-02T23:07:08.832504Z",
          "shell.execute_reply": "2024-07-02T23:07:08.941609Z"
        },
        "trusted": true,
        "id": "tpob80TIpHoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_cnn, y_test)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "# Plot the training history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T23:07:08.944767Z",
          "iopub.execute_input": "2024-07-02T23:07:08.945304Z",
          "iopub.status.idle": "2024-07-02T23:07:09.358778Z",
          "shell.execute_reply.started": "2024-07-02T23:07:08.945263Z",
          "shell.execute_reply": "2024-07-02T23:07:09.357486Z"
        },
        "trusted": true,
        "id": "xQZvcHTSpHoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Conclusion\n",
        "\n",
        "### Conclusion\n",
        "Using CNNs for tabular data can leverage their ability to capture local patterns and interactions, which might be missed by traditional models. This approach can potentially lead to better performance and more robust models for certain types of tabular datasets.\n",
        "\n",
        "**References:**\n",
        "- TensorFlow Documentation: [https://www.tensorflow.org/](https://www.tensorflow.org/)\n",
        "- Keras Documentation: [https://keras.io/](https://keras.io/)\n",
        "- Scikit-learn Documentation: [https://scikit-learn.org/](https://scikit-learn.org/)\n"
      ],
      "metadata": {
        "id": "nKgUWkiYpHoA"
      }
    }
  ]
}